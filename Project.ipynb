{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Codebase"]},{"cell_type":"markdown","metadata":{},"source":["Il file è ancora molto grezzo, e fatto per essere runnato su Kaggle."]},{"cell_type":"markdown","metadata":{},"source":["### Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:09.702867Z","iopub.status.busy":"2024-06-07T08:11:09.702481Z","iopub.status.idle":"2024-06-07T08:11:46.025120Z","shell.execute_reply":"2024-06-07T08:11:46.024145Z","shell.execute_reply.started":"2024-06-07T08:11:09.702833Z"},"trusted":true},"outputs":[],"source":["!pip install faiss-cpu \n","!pip install faiss-gpu \n","!pip install pytorch_metric_learning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:46.028141Z","iopub.status.busy":"2024-06-07T08:11:46.027728Z","iopub.status.idle":"2024-06-07T08:11:51.668046Z","shell.execute_reply":"2024-06-07T08:11:51.667211Z","shell.execute_reply.started":"2024-06-07T08:11:46.028104Z"},"trusted":true},"outputs":[],"source":["# Import libraries\n","import cv2\n","import faiss\n","import faiss.contrib.torch_utils\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision\n","import random\n","\n","from collections import defaultdict\n","from itertools import product\n","from PIL import Image,ImageDraw, ImageFont\n","from prettytable import PrettyTable\n","from pytorch_metric_learning import miners, losses\n","from pytorch_metric_learning.distances import CosineSimilarity, DotProductSimilarity\n","from sklearn.neighbors import NearestNeighbors\n","from skimage.transform import rescale\n","from torch.optim import SGD, Adam, AdamW, ASGD, RMSprop\n","from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torchvision import datasets, transforms, models\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:51.669433Z","iopub.status.busy":"2024-06-07T08:11:51.669070Z","iopub.status.idle":"2024-06-07T08:11:51.709766Z","shell.execute_reply":"2024-06-07T08:11:51.708805Z","shell.execute_reply.started":"2024-06-07T08:11:51.669409Z"},"trusted":true},"outputs":[],"source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:51.711036Z","iopub.status.busy":"2024-06-07T08:11:51.710750Z","iopub.status.idle":"2024-06-07T08:11:51.722722Z","shell.execute_reply":"2024-06-07T08:11:51.722103Z","shell.execute_reply.started":"2024-06-07T08:11:51.711000Z"},"trusted":true},"outputs":[],"source":["# Set all manual seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{},"source":["### Load Datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:51.725453Z","iopub.status.busy":"2024-06-07T08:11:51.725193Z","iopub.status.idle":"2024-06-07T08:11:51.731855Z","shell.execute_reply":"2024-06-07T08:11:51.731199Z","shell.execute_reply.started":"2024-06-07T08:11:51.725430Z"},"trusted":true},"outputs":[],"source":["# Transformations on images\n","transform = transforms.Compose([ \n","    # transforms.RandAugment(num_ops=3),  # applica tre operazioni di aumento casuale all’immagine\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:51.733145Z","iopub.status.busy":"2024-06-07T08:11:51.732800Z","iopub.status.idle":"2024-06-07T08:11:51.744214Z","shell.execute_reply":"2024-06-07T08:11:51.743400Z","shell.execute_reply.started":"2024-06-07T08:11:51.733114Z"},"trusted":true},"outputs":[],"source":["# Implementation of the train class \n","\n","class TrainDataset(Dataset):\n","    def __init__(self, root_dir, transform, img_per_place= 4):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.img_per_place= img_per_place #number of images to keep for the same id\n","        self.place_paths = defaultdict(list)\n","\n","        # Iteration loop trough all the directories of cities\n","        for city_dir in os.listdir(root_dir):\n","            city_path = os.path.join(root_dir, city_dir)\n","\n","            # Check if it's a directory\n","            if os.path.isdir(city_path):\n","                # Iteration loop trough all the images of a city\n","                for filename in os.listdir(city_path):\n","                    img_path = os.path.join(city_path, filename)\n","                    place_id = img_path.split(\"@\")[-2]\n","                    self.place_paths[place_id].append(img_path)\n","                    \n","        for place_id in list(self.place_paths.keys()):\n","            paths_place_id = self.place_paths[place_id]\n","            #keep only the places that have at least a minimum of 4 images per id\n","            if len(paths_place_id) < 4: \n","                del self.place_paths[place_id]\n","        self.places_ids = sorted(list(self.place_paths.keys()))\n","                 \n","                    \n","    def __getitem__(self, idx):\n","        place_id = self.places_ids[idx]\n","        paths_place_id = self.place_paths[place_id]\n","        #keep 4 random paths for each id\n","        chosen_paths = np.random.choice(paths_place_id, self.img_per_place)         \n","        images = [Image.open(path).convert('RGB') for path in chosen_paths]\n","        images = [self.transform(img) for img in images]\n","        return torch.stack(images), torch.tensor(idx).repeat(self.img_per_place), place_id\n","    \n","    def __len__(self):\n","        return len(self.places_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:51.745545Z","iopub.status.busy":"2024-06-07T08:11:51.745295Z","iopub.status.idle":"2024-06-07T08:11:51.760204Z","shell.execute_reply":"2024-06-07T08:11:51.759313Z","shell.execute_reply.started":"2024-06-07T08:11:51.745524Z"},"trusted":true},"outputs":[],"source":["# Implementation of the evaluation classes (validation,test)\n","\n","class EvalDataset(data.Dataset):\n","    def __init__(self, root_dir,type_of_set,transform):\n","        self.root_dir = root_dir\n","        self.type_of_set = type_of_set\n","        self.transform = transform\n","\n","        if (type_of_set != 'val') and (type_of_set != 'test'):\n","            raise ValueError(f\"Type of set not valid,try 'val' or 'test'\")\n","        else:\n","            path_directory = os.path.join(root_dir,type_of_set)\n","            database_dir = os.path.join(path_directory,'database')\n","            queries_dir = os.path.join(path_directory, 'queries')\n","\n","        self.database_paths = []\n","        for filename in os.listdir(database_dir):\n","            img_path = os.path.join(database_dir, filename)\n","            self.database_paths.append(img_path)\n","        self.queries_paths = []\n","        for filename in os.listdir(queries_dir):\n","            img_path = os.path.join(queries_dir, filename)\n","            self.queries_paths.append(img_path)\n","\n","        self.database_coordinates = np.array \\\n","            ([(path.split(\"@\")[1], path.split(\"@\")[2]) for path in self.database_paths]).astype(float)\n","        \n","        self.queries_coordinates = np.array\\\n","            ([(path.split(\"@\")[1], path.split(\"@\")[2]) for path in self.queries_paths]).astype(float)\n","\n","        # Find positives_per_query, which are within positive_dist_threshold (default 25 meters)\n","        knn = NearestNeighbors(n_jobs=-1)\n","        knn.fit(self.database_coordinates)\n","        self.positives_per_query = knn.radius_neighbors(self.queries_coordinates,\n","                                                        radius=25,\n","                                                        return_distance=False)\n","        # Create a unique list to ease the __getitem__\n","        self.all_images_paths = [path for path in self.database_paths]\n","        self.all_images_paths += [path for path in self.queries_paths]\n","\n","        self.database_num = len(self.database_paths)\n","        self.queries_num = len(self.queries_paths)\n","\n","\n","    def __getitem__(self, idx):\n","        image_path = self.all_images_paths[idx]\n","        image = self.transform(Image.open(image_path).convert('RGB'))\n","        return image, idx\n","\n","    def __len__(self):\n","        return len(self.all_images_paths)\n","    \n","    #forse si potrebbe togliere\n","    def __repr__(self):\n","        return f\" <{self.type_of_set}; - #q: {self.queries_num}; #db: {self.database_num} >\"\n","\n","    def get_positives(self):\n","        return self.positives_per_query"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:11:51.761392Z","iopub.status.busy":"2024-06-07T08:11:51.761151Z","iopub.status.idle":"2024-06-07T08:12:04.716709Z","shell.execute_reply":"2024-06-07T08:12:04.715824Z","shell.execute_reply.started":"2024-06-07T08:11:51.761369Z"},"trusted":true},"outputs":[],"source":["# Training loading\n","root_dir_train = '/kaggle/input/gsv-xs/gsv_xs/train'\n","dataset_train = TrainDataset(root_dir=root_dir_train, transform=transform)\n","dataloader_train = data.DataLoader(dataset_train, batch_size=64, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:04.718197Z","iopub.status.busy":"2024-06-07T08:12:04.717880Z","iopub.status.idle":"2024-06-07T08:12:05.192179Z","shell.execute_reply":"2024-06-07T08:12:05.191397Z","shell.execute_reply.started":"2024-06-07T08:12:04.718171Z"},"trusted":true},"outputs":[],"source":["#Validation loading\n","root_dir_eval = '/kaggle/input/sf-xs/sf_xs'\n","dataset_val = EvalDataset(root_dir=root_dir_eval, type_of_set= 'val', transform=transform)\n","dataloader_val = data.DataLoader(dataset_val, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:05.193525Z","iopub.status.busy":"2024-06-07T08:12:05.193265Z","iopub.status.idle":"2024-06-07T08:12:06.277765Z","shell.execute_reply":"2024-06-07T08:12:06.276760Z","shell.execute_reply.started":"2024-06-07T08:12:05.193502Z"},"trusted":true},"outputs":[],"source":["#Test loading\n","\n","#SF-XS\n","root_dir_eval = '/kaggle/input/sf-xs/sf_xs'\n","dataset_test = EvalDataset(root_dir=root_dir_eval, type_of_set= 'test', transform=transform)\n","dataloader_test = data.DataLoader(dataset_test, batch_size=64, shuffle=False)\n","\n","#Tokyo-xs\n","root_dir_tokyo = '/kaggle/input/tokyo-xs/tokyo_xs'\n","dataset_tokyo = EvalDataset(root_dir=root_dir_tokyo, type_of_set= 'test', transform=transform)\n","dataloader_tokyo = data.DataLoader(dataset_tokyo, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Models (only GeM for the moment)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:06.322709Z","iopub.status.busy":"2024-06-07T08:12:06.322436Z","iopub.status.idle":"2024-06-07T08:12:06.334512Z","shell.execute_reply":"2024-06-07T08:12:06.333671Z","shell.execute_reply.started":"2024-06-07T08:12:06.322686Z"},"trusted":true},"outputs":[],"source":["def get_backbone():                            \n","    backbone = torchvision.models.resnet18(pretrained=True)     \n","    for name, child in backbone.named_children(): \n","                                                            \n","            if name == \"layer3\":  # Freeze layers before conv_3\n","                break                                                \n","            for params in child.parameters():                       \n","                params.requires_grad = False                           \n","\n","    layers = list(backbone.children())[:7]                     \n","    \n","    backbone = torch.nn.Sequential(*layers)                         \n","    \n","    return backbone"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:06.335907Z","iopub.status.busy":"2024-06-07T08:12:06.335647Z","iopub.status.idle":"2024-06-07T08:12:06.347528Z","shell.execute_reply":"2024-06-07T08:12:06.346736Z","shell.execute_reply.started":"2024-06-07T08:12:06.335885Z"},"trusted":true},"outputs":[],"source":["class Flatten(nn.Module):                       \n","    def __init__(self):\n","        super().__init__()                      \n","    \n","    def forward(self, x):\n","        assert x.shape[2] == x.shape[3] == 1, f\"{x.shape[2]} != {x.shape[3]} != 1\"  \n","        return x[:, :, 0, 0]\n","    \n","class L2Norm(nn.Module):                        \n","    def __init__(self, dim=1):\n","        super().__init__()\n","        self.dim = dim                        \n","    \n","    def forward(self, x):\n","        return F.normalize(x, p=2.0, dim=self.dim)  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:07.289932Z","iopub.status.busy":"2024-06-07T08:12:07.289668Z","iopub.status.idle":"2024-06-07T08:12:07.581298Z","shell.execute_reply":"2024-06-07T08:12:07.580387Z","shell.execute_reply.started":"2024-06-07T08:12:07.289910Z"},"trusted":true},"outputs":[],"source":["# Gem pooling layer to obtain the final embedding\n","\n","class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super(GeM,self).__init__()\n","        self.p = nn.Parameter(torch.ones(1)*p)\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        return self.gem(x, p=self.p, eps=self.eps)\n","        \n","    def gem(self, x, p=3, eps=1e-6):\n","        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n","    \n","    def __repr__(self):\n","        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n","\n","gem_pool = GeM()\n","\n","# Network with truncated ResNet-18 followed by gem pooling\n","class GeM_ResNet(nn.Module):\n","    def __init__(self):\n","        super(GeM_ResNet, self).__init__()\n","        # Load the pretrained ResNet-18 model\n","        self.backbone = get_backbone()\n","        self.aggregation = nn.Sequential(                \n","                # L2Norm(),                                  \n","                gem_pool,\n","                Flatten(),\n","                nn.Linear(256, 256),    \n","                # L2Norm()                                   \n","            )                                               \n","\n","    def forward(self, x):\n","        x = self.backbone(x)                                \n","        x = self.aggregation(x)                             \n","        return x    \n","\n","# Initialize the network\n","if torch.cuda.device_count() > 1:\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs\")\n","    model_gem = nn.DataParallel(GeM_ResNet())\n","    model_gem = model_gem.cuda()\n","else:\n","    model_gem = GeM_ResNet().cuda()\n","# print(model_gem)\n","# torch.save(model_gem.state_dict(), '/kaggle/working/initial_weights.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:35:57.879176Z","iopub.status.busy":"2024-06-07T08:35:57.878816Z","iopub.status.idle":"2024-06-07T08:35:57.886655Z","shell.execute_reply":"2024-06-07T08:35:57.885713Z","shell.execute_reply.started":"2024-06-07T08:35:57.879151Z"},"trusted":true},"outputs":[],"source":["def knn_search(proxies, proxy_labels):\n","    informative_batches = []\n","    k=60\n","    while len(proxies) > k:\n","        # Create an index object with a flat L2 distance metric\n","        faiss_index = faiss.IndexFlatL2(proxies.shape[1])\n","\n","        # Add the vectors to the index\n","        faiss_index.add(proxies)\n","\n","        # Define a query vector\n","        query_vector = proxies[0]\n","        query_vector = np.reshape(query_vector, (1, -1))\n","\n","        distances, indices = faiss_index.search(query_vector, k)\n","        indices_list = [indices[0][:][i] for i in range(k)]\n","\n","        informative_batches_labels = [proxy_labels[idx] for idx in indices_list]\n","        informative_batches.append(informative_batches_labels)\n","        \n","        proxies = np.delete(proxies, indices_list, axis=0)\n","        proxy_labels = np.delete(proxy_labels, indices_list, axis=0)\n","    \n","    return informative_batches"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:38:45.056150Z","iopub.status.busy":"2024-06-07T08:38:45.055567Z","iopub.status.idle":"2024-06-07T08:38:45.083845Z","shell.execute_reply":"2024-06-07T08:38:45.082748Z","shell.execute_reply.started":"2024-06-07T08:38:45.056102Z"},"trusted":true},"outputs":[],"source":["# PROXY\n","def training_loop(epoch,model,dataloader,criterion, optimizer, miner = None, pre_miner = None):\n","    \n","    model.train()\n","    inf_batch_count = 0\n","    train_loss = 0\n","        \n","    if epoch == 1 or pre_miner is None:\n","        if pre_miner is not None:\n","            global informative_batches\n","            informative_batches = []\n","            proxy_labels = []\n","            proxies = []\n","        for batch_idx, batch in enumerate(dataloader):\n","            optimizer.zero_grad()\n","\n","            images, labels, _ = batch\n","\n","            num_places, num_images_per_place, C, H, W = images.shape\n","\n","            images = images.view(num_places * num_images_per_place, C, H, W)\n","            labels = labels.view(num_places * num_images_per_place)\n","\n","            descriptors = model(images.to(device)).cpu()\n","\n","            if pre_miner is not None:\n","                num_tensori, *_ = descriptors.shape\n","                for i in range(0, num_tensori - 4 + 1, 4):\n","                    place_images = descriptors[i:i+4]\n","                    proxy = place_images.mean(dim=0).tolist()\n","                    proxies.append(proxy)\n","                    proxy_labels.append(int(labels[i]))\n","\n","            # MINING: we mine the pairs/triplets if there is an online mining strategy\n","            if miner is not None:\n","                miner_outputs = miner(descriptors, labels.to(device))\n","                loss = criterion(descriptors, labels.to(device), miner_outputs)\n","\n","                # calculate the % of trivial pairs/triplets which do not contribute in the loss value\n","                nb_samples = descriptors.shape[0]\n","                nb_mined = len(set(miner_outputs[0].detach().cpu().numpy()))\n","                batch_acc = 1.0 - (nb_mined / nb_samples)\n","\n","            else: # no online mining\n","                loss = criterion(descriptors, labels.to(device))\n","                batch_acc = 0.0\n","            \n","            \n","            loss.backward() \n","            optimizer.step()\n","            train_loss += loss.item()\n","            # print(f'Batch {batch_idx}, Loss: {loss.item()}')\n","\n","        if pre_miner is not None:\n","            proxies = np.asarray(proxies, dtype = np.float32)\n","            proxy_labels = np.asarray(proxy_labels, dtype = np.int32)\n","            informative_batches = knn_search(proxies, proxy_labels)\n","        \n","      \n","        \n","    else:\n","        proxy_labels = []\n","        proxies = []\n","        for batch in informative_batches:            \n","            # print(batch)\n","            optimizer.zero_grad()\n","\n","            images = [dataset_train.__getitem__(label)[0] for label in batch]\n","            \n","            images = torch.stack(images)\n","            dimensions = images.shape\n","            labels = [torch.tensor(label).repeat(4) for label in batch]\n","            labels = torch.stack(labels)\n","\n","\n","            num_places, num_images_per_place, C, H, W = images.shape\n","\n","            images = images.view(num_places * num_images_per_place, C, H, W)\n","            labels = labels.view(num_places * num_images_per_place)\n","\n","            descriptors = model(images.to(device)).cpu()\n","\n","            num_tensori, *_ = descriptors.shape\n","            for i in range(0, num_tensori - 4 + 1, 4):\n","                place_images = descriptors[i:i+4]\n","                proxy = place_images.mean(dim=0).tolist()\n","                proxies.append(proxy)\n","                proxy_labels.append(int(labels[i]))\n","\n","            # MINING: we mine the pairs/triplets if there is an online mining strategy\n","            if miner is not None:\n","                miner_outputs = miner(descriptors, labels.to(device))\n","                loss = criterion(descriptors, labels.to(device), miner_outputs)\n","\n","                # calculate the % of trivial pairs/triplets which do not contribute in the loss value\n","                nb_samples = descriptors.shape[0]\n","                nb_mined = len(set(miner_outputs[0].detach().cpu().numpy()))\n","                batch_acc = 1.0 - (nb_mined / nb_samples)\n","\n","            else: # no online mining\n","                loss = criterion(descriptors, labels.to(device))\n","                batch_acc = 0.0\n","                \n","\n","            loss.backward() \n","            optimizer.step()\n","            train_loss += loss.item()\n","            inf_batch_count += 1\n","            # print(f'Batch {batch_idx}, Loss: {loss.item()}')\n","\n","\n","        proxies = np.asarray(proxies, dtype = np.float32)\n","        proxy_labels = np.asarray(proxy_labels, dtype = np.int32)\n","\n","        informative_batches = knn_search(proxies, proxy_labels)\n","\n","    train_loss = train_loss / len(dataloader)\n","    print(f'Train Epoch: {epoch} Loss: {train_loss:.6f}')\n","    #print(informative_batches, len(informative_batches),len(informative_batches[5]))\n","    # return train_loss"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualization of results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:07.637109Z","iopub.status.busy":"2024-06-07T08:12:07.636797Z","iopub.status.idle":"2024-06-07T08:12:07.657950Z","shell.execute_reply":"2024-06-07T08:12:07.657026Z","shell.execute_reply.started":"2024-06-07T08:12:07.637080Z"},"trusted":true},"outputs":[],"source":["# Height and width of a single image\n","Height = 1024\n","Width = 1024\n","\n","Total_height = 350 #height of the resulting collage of photos with text\n","fontsize = 100\n","space = 150  # Space between two images\n","\n","def write_labels_to_image(labels=[\"text1\", \"text2\"]):\n","\n","    # Load the font\n","    font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", fontsize)\n","    \n","    # Calculate the width of the resulting image\n","    img_width = Width * len(labels) + space * (len(labels) - 1)\n","    img_height = Total_height\n","    \n","    # Create a new image with white background\n","    background_color = (1, 1, 1) #white\n","    img = Image.new('RGB', (img_width, img_height), background_color)\n","    draw = ImageDraw.Draw(img)\n","    \n","    # Draw each label\n","    for i, text in enumerate(labels):\n","        _, _,text_width, text_height = draw.textbbox((0,0), text, font=font)\n","        x = (Width + space) * i + Width //2 - text_width // 2\n","        y = (img_height - text_height) // 2\n","        draw.text((x, y), text, fill=(0, 0, 0), font=font)\n","    \n","    return np.array(img)\n","\n","\n","def draw_box(img, c): #create a coloured box around the image\n","    thickness=5\n","    height, width = img.shape[:2]\n","    cv2.line(img, (0, 0), (0, height), c, thickness) #left vertical line\n","    cv2.line(img, (0, height), (width, height), c, thickness) #upper horizontal line\n","    cv2.line(img, (width, height), (width, 0), c, thickness) #right vertical line\n","    cv2.line(img, (width, 0), (0, 0), c, thickness) #lower horizontal line\n","    return img\n","\n","\n","def print_preds(predictions, test_dataset,number_of_images_per_epoch):\n","    x=0 \n","    #take the true positive of the query\n","    positives_per_query = test_dataset.get_positives()\n","    for q_idx, preds in enumerate(predictions):\n","        if x>=number_of_images_per_epoch:\n","            break\n","        query_path = test_dataset.queries_paths[q_idx]\n","        list_of_images_paths = [query_path]\n","        # List of None (query), True (correct preds) or False (wrong preds)\n","        preds_types = [None]\n","        for _ , pred in enumerate(preds):\n","            pred_path = test_dataset.database_paths[pred]\n","            list_of_images_paths.append(pred_path) #list of query path + paths of all its predictions\n","            if pred in positives_per_query[q_idx]: #check if the prediction is correct, comparing to true positives\n","                type_of_pred = True\n","            else:\n","                type_of_pred = False\n","            preds_types.append(type_of_pred)\n","              \n","        labels = [\"Query\"] + [f\"Prediction{i} - {type_of_pred}\" for i, type_of_pred in enumerate(preds_types[1:])]\n","        num_images = len(list_of_images_paths)\n","        color=[]\n","        images = [np.array(Image.open(path)) for path in list_of_images_paths]\n","        for img, correct in zip(images, preds_types):\n","            if correct is not None: #check if it's a query or not\n","                if correct:\n","                    color = (0, 255, 0)  # Green for correct\n","                else:\n","                    color = (255, 0, 0)  # Red for wrong\n","            draw_box(img, color)\n","        concat_image = np.ones([Height, (num_images*Width)+((num_images-1)*space), 3])\n","        \n","        #rescaling the images to the same dimentions dim\n","        rescaleds = [rescale(i, [min(Height/i.shape[0], Width/i.shape[1]), min(Height/i.shape[0], Width/i.shape[1]), 1]) for i in images]\n","        \n","        #zero padding needed to center the image \n","        for i, image in enumerate(rescaleds):\n","            pad_width = (Width - image.shape[1] + 1) // 2\n","            pad_height = (Height - image.shape[0] + 1) // 2\n","            image = np.pad(image, [[pad_height, pad_height], [pad_width, pad_width], [0, 0]], constant_values=1)[:Height, :Width]\n","            concat_image[: , i*(Width+space) : i*(Width+space)+Width] = image\n","            \n","        labels_image = write_labels_to_image(labels)\n","        final_image = np.concatenate([labels_image, concat_image])\n","        final_image = Image.fromarray((final_image*255).astype(np.uint8))\n","        plt.figure()\n","        plt.imshow(final_image)\n","        plt.axis('off')\n","        plt.show()\n","        x = x+1"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:07.659729Z","iopub.status.busy":"2024-06-07T08:12:07.659120Z","iopub.status.idle":"2024-06-07T08:12:07.672504Z","shell.execute_reply":"2024-06-07T08:12:07.671754Z","shell.execute_reply.started":"2024-06-07T08:12:07.659697Z"},"trusted":true},"outputs":[],"source":["def recall(dataset, database_descriptors, queries_descriptors, k_values, print_predictions, number_of_images_per_epoch):\n","    #use faiss to optimize the research\n","    faiss_index = faiss.IndexFlatL2(queries_descriptors.shape[1])\n","    faiss_index.add(database_descriptors)\n","    del database_descriptors\n","    \n","    _, predictions = faiss_index.search(queries_descriptors, max(k_values))\n"," \n","    positives_per_query = dataset.get_positives()\n","    recalls = np.zeros(len(k_values))\n","        \n","    # Calculate recall \n","    for q_idx, pred in enumerate(predictions):\n","        for i, n in enumerate(k_values):\n","            if np.any(np.in1d(pred[:n], positives_per_query[q_idx])):\n","                recalls[i:] += 1\n","                break\n","                \n","    recalls = recalls / dataset.queries_num * 100    \n","    if print_predictions == True:\n","        # For each query save 3 predictions\n","        print_preds(predictions[:, :3],dataset,number_of_images_per_epoch)\n","\n","    table = PrettyTable()\n","    table.field_names = ['K']+[str(k) for k in k_values]\n","    table.add_row(['Recall@K']+ [f'{values:.2f}' for values in recalls])\n","    print(table)\n","    return recalls"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:07.673756Z","iopub.status.busy":"2024-06-07T08:12:07.673496Z","iopub.status.idle":"2024-06-07T08:12:07.686673Z","shell.execute_reply":"2024-06-07T08:12:07.685954Z","shell.execute_reply.started":"2024-06-07T08:12:07.673734Z"},"trusted":true},"outputs":[],"source":["def evaluation_loop(dataset, model, dataloader, k_values,print_predictions, number_of_images_per_epoch = 5):\n","    model.eval()\n","    recalls = np.zeros(len(k_values))\n","    sum_recalls = np.zeros(len(k_values))\n","    all_descriptors = []\n","    for batch_idx, batch in enumerate(dataloader):\n","        images, _ = batch\n","    \n","        # Calcola i descrittori utilizzando il modello\n","        descriptors = model(images.to(device)).cpu().detach().numpy().astype(np.float32)\n","\n","        # Concatena i descrittori alla lista dei descrittori concatenati\n","        all_descriptors.append(descriptors)  # Aggiungi i descrittori calcolati alla lista dei descrittori\n","        concatenated_descriptors = np.concatenate(all_descriptors, axis=0) \n","       # print(concatenated_descriptors.shape[0])\n","    database_descriptors = concatenated_descriptors[: dataset.database_num ]\n","    queries_descriptors = concatenated_descriptors[dataset.database_num :]\n","        \n","    recalls = recall(dataset, database_descriptors, queries_descriptors, k_values, print_predictions, number_of_images_per_epoch)\n","    # print(f'R@{k_values[0]}: {recalls[0]:.6f} ; R@{k_values[1]}: {recalls[1]:.6f} ; R@{k_values[2]}: {recalls[2]:.6f};')\n","    return recalls"]},{"cell_type":"markdown","metadata":{},"source":["## Training/Validation session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-07T08:12:07.688275Z","iopub.status.busy":"2024-06-07T08:12:07.687708Z","iopub.status.idle":"2024-06-07T08:12:07.702253Z","shell.execute_reply":"2024-06-07T08:12:07.701398Z","shell.execute_reply.started":"2024-06-07T08:12:07.688245Z"},"trusted":true},"outputs":[],"source":["# Criterion\n","criterion = losses.ContrastiveLoss(pos_margin=0, neg_margin=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["k_values= [1,5]\n","# Parametri per la grid search\n","learning_rates = [1e-4] \n","weight_decays = [1e-3]  \n","optimizers = ['Adam']  #, 'AdamW']  # best optimizers\n","# momentums = [0, 0.95]  # [0.0, 0.8, 0.9, 0.95]  \n","schedulers = ['None','CosineAnnealingLR']\n","\n","# Risultati della grid search\n","results = []\n","\n","# Loop di grid search\n","for lr, wd, opt_name, sched_name in product(learning_rates, weight_decays, optimizers, schedulers):\n","    print(f'Running with LR={lr}, WD={wd}, Optimizer={opt_name}, Scheduler={sched_name}')\n","    \n","    # Scegli l'ottimizzatore\n","    if opt_name == 'Adam':\n","        optimizer = optim.Adam(model_gem.parameters(), lr=lr, weight_decay=wd)\n","\n","    # Scegli lo scheduler\n","    if sched_name == 'CosineAnnealingLR':\n","        scheduler = CosineAnnealingLR(optimizer, T_max=10, verbose=True)\n","    \n","    # Loop di addestramento\n","    num_epochs = 10\n","    print('\\033[1;31mRESULTS ON TRAINING\\033[0m')\n","    for epoch in tqdm(range(1,11)):\n","        training_loss = training_loop(epoch, model_gem, dataloader_train, criterion, optimizer,pre_miner = 'Proxy')                   \n","        if sched_name == 'CosineAnnealingLR':            \n","            scheduler.step()\n","    \n","    recalls = evaluation_loop(dataset_val, model_gem, dataloader_val, k_values, False)\n","    model_gem.load_state_dict(torch.load('/kaggle/input/initial-weights-gem-parallel/initial_weights_gem_parallel.pth'))  \n","\n","    # Salva i risultati\n","    results.append({\n","        'optimizer': opt_name,\n","        'recall@1': recalls[0],\n","        'recall@5': recalls[1]\n","    })\n","    \n","# Stampa i risultati finali\n","for result in results:\n","    print(result)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4852937,"sourceId":8193768,"sourceType":"datasetVersion"},{"datasetId":4986083,"sourceId":8383866,"sourceType":"datasetVersion"},{"datasetId":4996962,"sourceId":8398939,"sourceType":"datasetVersion"},{"datasetId":5130599,"sourceId":8579221,"sourceType":"datasetVersion"},{"datasetId":5133316,"sourceId":8583251,"sourceType":"datasetVersion"},{"datasetId":5167427,"sourceId":8630340,"sourceType":"datasetVersion"},{"datasetId":5167467,"sourceId":8630390,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
